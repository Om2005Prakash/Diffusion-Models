{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import os\n",
    "\n",
    "class ComplexCNN(nn.Module):\n",
    "    def __init__(self, dropout_rate=0.5):\n",
    "        super(ComplexCNN, self).__init__()\n",
    "        # Input: 3x32x32\n",
    "\n",
    "        # Convolutional Block 1\n",
    "        self.conv1a = nn.Conv2d(3, 64, kernel_size=3, padding=1) # 3 -> 64 filters\n",
    "        self.bn1a = nn.BatchNorm2d(64)\n",
    "        self.conv1b = nn.Conv2d(64, 64, kernel_size=3, padding=1)\n",
    "        self.bn1b = nn.BatchNorm2d(64)\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2) # 32x32 -> 16x16\n",
    "\n",
    "        # Convolutional Block 2\n",
    "        self.conv2a = nn.Conv2d(64, 128, kernel_size=3, padding=1) # 64 -> 128 filters\n",
    "        self.bn2a = nn.BatchNorm2d(128)\n",
    "        self.conv2b = nn.Conv2d(128, 128, kernel_size=3, padding=1)\n",
    "        self.bn2b = nn.BatchNorm2d(128)\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2) # 16x16 -> 8x8\n",
    "\n",
    "        # Convolutional Block 3\n",
    "        self.conv3a = nn.Conv2d(128, 256, kernel_size=3, padding=1) # 128 -> 256 filters\n",
    "        self.bn3a = nn.BatchNorm2d(256)\n",
    "        self.conv3b = nn.Conv2d(256, 256, kernel_size=3, padding=1)\n",
    "        self.bn3b = nn.BatchNorm2d(256)\n",
    "        self.pool3 = nn.MaxPool2d(kernel_size=2, stride=2) # 8x8 -> 4x4\n",
    "\n",
    "        # Convolutional Block 4\n",
    "        self.conv4a = nn.Conv2d(256, 512, kernel_size=3, padding=1) # 256 -> 512 filters\n",
    "        self.bn4a = nn.BatchNorm2d(512)\n",
    "        self.conv4b = nn.Conv2d(512, 512, kernel_size=3, padding=1)\n",
    "        self.bn4b = nn.BatchNorm2d(512)\n",
    "        self.pool4 = nn.MaxPool2d(kernel_size=2, stride=2) # 4x4 -> 2x2\n",
    "\n",
    "        # Convolutional Block 5\n",
    "        self.conv5a = nn.Conv2d(512, 512, kernel_size=3, padding=1) # 512 -> 512 filters\n",
    "        self.bn5a = nn.BatchNorm2d(512)\n",
    "        self.conv5b = nn.Conv2d(512, 512, kernel_size=3, padding=1)\n",
    "        self.bn5b = nn.BatchNorm2d(512)\n",
    "        # No pool after block 5, keep 2x2\n",
    "\n",
    "        # --- ADDED: Convolutional Block 6 ---\n",
    "        self.conv6a = nn.Conv2d(512, 512, kernel_size=3, padding=1) # 512 -> 512 filters\n",
    "        self.bn6a = nn.BatchNorm2d(512)\n",
    "        self.conv6b = nn.Conv2d(512, 512, kernel_size=3, padding=1)\n",
    "        self.bn6b = nn.BatchNorm2d(512)\n",
    "\n",
    "        self.gap = nn.AdaptiveAvgPool2d((1, 1))\n",
    "\n",
    "        self.flattened_size = 512\n",
    "\n",
    "        self.fc1 = nn.Linear(self.flattened_size, 512) # Input 512\n",
    "        self.bn_fc1 = nn.BatchNorm1d(512)\n",
    "        self.dropout = nn.Dropout(dropout_rate) # Consider adjusting dropout rate\n",
    "        self.fc2 = nn.Linear(512, 10) # Output 10 classes\n",
    "\n",
    "\n",
    "    def _forward_features(self, x):\n",
    "        # Block 1\n",
    "        x = F.relu(self.bn1a(self.conv1a(x)))\n",
    "        x = F.relu(self.bn1b(self.conv1b(x)))\n",
    "        x = self.pool1(x)\n",
    "        # Block 2\n",
    "        x = F.relu(self.bn2a(self.conv2a(x)))\n",
    "        x = F.relu(self.bn2b(self.conv2b(x)))\n",
    "        x = self.pool2(x)\n",
    "        # Block 3\n",
    "        x = F.relu(self.bn3a(self.conv3a(x)))\n",
    "        x = F.relu(self.bn3b(self.conv3b(x)))\n",
    "        x = self.pool3(x)\n",
    "        # Block 4\n",
    "        x = F.relu(self.bn4a(self.conv4a(x)))\n",
    "        x = F.relu(self.bn4b(self.conv4b(x)))\n",
    "        x = self.pool4(x)\n",
    "        # Block 5\n",
    "        x = F.relu(self.bn5a(self.conv5a(x)))\n",
    "        x = F.relu(self.bn5b(self.conv5b(x)))\n",
    "        # --- ADDED: Block 6 Forward Pass ---\n",
    "        x = F.relu(self.bn6a(self.conv6a(x)))\n",
    "        x = F.relu(self.bn6b(self.conv6b(x)))\n",
    "        return x\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self._forward_features(x)\n",
    "        x = self.gap(x)\n",
    "        x = x.view(-1, self.flattened_size)\n",
    "        x = F.relu(self.bn_fc1(self.fc1(x)))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# --- Configuration ---\n",
    "batch_size = 128 \n",
    "epochs = 100     \n",
    "learning_rate = 0.001 \n",
    "weight_decay = 5e-4  \n",
    "dropout_rate = 0.5  \n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "\n",
    "cifar_mean = (0.4914, 0.4822, 0.4465)\n",
    "cifar_std = (0.2023, 0.1994, 0.2010)\n",
    "\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(cifar_mean, cifar_std)\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(cifar_mean, cifar_std)\n",
    "])\n",
    "\n",
    "train_dataset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)\n",
    "test_dataset = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)\n",
    "\n",
    "# Adjust num_workers based on your system\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4, pin_memory=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size*2, shuffle=False, num_workers=4, pin_memory=True) # Can use larger batch for testing\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "# --- Initialize Model, Loss, Optimizer ---\n",
    "model = ComplexCNN(dropout_rate=dropout_rate).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay) # Using Adam here\n",
    "\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs, eta_min=1e-6) # Adjust T_max if changing epochs\n",
    "\n",
    "# --- Training Loop ---\n",
    "def train(epoch):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device, non_blocking=True), target.to(device, non_blocking=True)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = output.max(1)\n",
    "        total += target.size(0)\n",
    "        correct += predicted.eq(target).sum().item()\n",
    "\n",
    "        if (batch_idx + 1) % 100 == 0:\n",
    "            batch_acc = 100. * correct / total\n",
    "            print(f'Train Epoch: {epoch} [{batch_idx * len(data)}/{len(train_loader.dataset)} ({100. * batch_idx / len(train_loader):.0f}%)]\\tLoss: {running_loss / 100:.6f}\\tAcc: {batch_acc:.2f}%')\n",
    "            running_loss = 0.0\n",
    "\n",
    "    if scheduler:\n",
    "        scheduler.step()\n",
    "\n",
    "# --- Evaluation Loop ---\n",
    "def test():\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device, non_blocking=True), target.to(device, non_blocking=True)\n",
    "            output = model(data)\n",
    "            batch_loss = criterion(output, target).item()\n",
    "            test_loss += batch_loss * data.size(0)\n",
    "            pred = output.argmax(dim=1, keepdim=True)\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    accuracy = 100. * correct / len(test_loader.dataset)\n",
    "    print(f'\\nTest set: Average loss: {test_loss:.4f}, Accuracy: {correct}/{len(test_loader.dataset)} ({accuracy:.2f}%)\\n')\n",
    "    return accuracy, test_loss\n",
    "\n",
    "# --- Run Training and Testing ---\n",
    "best_accuracy = 0.0\n",
    "# --- UPDATED Save path as requested ---\n",
    "model_save_path = 'cifar_10_cnn.pth'\n",
    "\n",
    "print(f\"Starting training for {epochs} epochs...\")\n",
    "for epoch in range(1, epochs + 1):\n",
    "    train(epoch)\n",
    "    current_accuracy, current_loss = test()\n",
    "\n",
    "    print(f\"Epoch {epoch}: Test Acc = {current_accuracy:.2f}%, Test Loss = {current_loss:.4f}, LR = {optimizer.param_groups[0]['lr']:.6f}\")\n",
    "\n",
    "    # Save the Best Model\n",
    "    if current_accuracy > best_accuracy:\n",
    "        best_accuracy = current_accuracy\n",
    "        torch.save(model.state_dict(), model_save_path)\n",
    "        print(f\"----> Saved new best model to {model_save_path} with accuracy {best_accuracy:.2f}% <----\")\n",
    "\n",
    "print(\"Training finished.\")\n",
    "print(f\"Best model saved to {model_save_path} with accuracy {best_accuracy:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Classifier model loaded from cifar_10_cnn.pth (6-Block CNN)\n",
      "Found 5760 images in ./DDPM_CIFAR10_Clean\n",
      "Running inference on generated images using 6-Block CNN...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 100%|██████████| 45/45 [00:00<00:00, 58.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully processed 5760 valid images for IS calculation.\n",
      "Calculating Inception Score (Single Split) using 6-Block CNN...\n",
      "Image Source: ./DDPM_CIFAR10_Clean\n",
      "Model Path:   cifar_10_cnn.pth\n",
      "Mean IS:      5.0878\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "import os\n",
    "import numpy as np\n",
    "from scipy.stats import entropy\n",
    "from tqdm import tqdm\n",
    "import sys\n",
    "\n",
    "# --- Configuration ---\n",
    "IMAGE_DIR = './DDPM_CIFAR10_Clean' \n",
    "MODEL_PATH = 'cifar_10_cnn.pth'    \n",
    "BATCH_SIZE = 128                   \n",
    "NUM_WORKERS = 4\n",
    "\n",
    "# --- 1. Define Model Architecture (MUST MATCH the saved cifar_10_cnn.pth model) ---\n",
    "\n",
    "class ComplexCNN(nn.Module):\n",
    "    def __init__(self, dropout_rate=0.5):\n",
    "        super(ComplexCNN, self).__init__()\n",
    "        self.conv1a = nn.Conv2d(3, 64, kernel_size=3, padding=1); self.bn1a = nn.BatchNorm2d(64)\n",
    "        self.conv1b = nn.Conv2d(64, 64, kernel_size=3, padding=1); self.bn1b = nn.BatchNorm2d(64)\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2) # 32x32 -> 16x16\n",
    "        self.conv2a = nn.Conv2d(64, 128, kernel_size=3, padding=1); self.bn2a = nn.BatchNorm2d(128)\n",
    "        self.conv2b = nn.Conv2d(128, 128, kernel_size=3, padding=1); self.bn2b = nn.BatchNorm2d(128)\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2) # 16x16 -> 8x8\n",
    "        self.conv3a = nn.Conv2d(128, 256, kernel_size=3, padding=1); self.bn3a = nn.BatchNorm2d(256)\n",
    "        self.conv3b = nn.Conv2d(256, 256, kernel_size=3, padding=1); self.bn3b = nn.BatchNorm2d(256)\n",
    "        self.pool3 = nn.MaxPool2d(kernel_size=2, stride=2) # 8x8 -> 4x4\n",
    "        self.conv4a = nn.Conv2d(256, 512, kernel_size=3, padding=1); self.bn4a = nn.BatchNorm2d(512)\n",
    "        self.conv4b = nn.Conv2d(512, 512, kernel_size=3, padding=1); self.bn4b = nn.BatchNorm2d(512)\n",
    "        self.pool4 = nn.MaxPool2d(kernel_size=2, stride=2) # 4x4 -> 2x2\n",
    "        self.conv5a = nn.Conv2d(512, 512, kernel_size=3, padding=1); self.bn5a = nn.BatchNorm2d(512)\n",
    "        self.conv5b = nn.Conv2d(512, 512, kernel_size=3, padding=1); self.bn5b = nn.BatchNorm2d(512)\n",
    "        self.conv6a = nn.Conv2d(512, 512, kernel_size=3, padding=1); self.bn6a = nn.BatchNorm2d(512)\n",
    "        self.conv6b = nn.Conv2d(512, 512, kernel_size=3, padding=1); self.bn6b = nn.BatchNorm2d(512)\n",
    "        self.gap = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.flattened_size = 512\n",
    "        self.fc1 = nn.Linear(self.flattened_size, 512); self.bn_fc1 = nn.BatchNorm1d(512)\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        self.fc2 = nn.Linear(512, 10)\n",
    "\n",
    "    def _forward_features(self, x):\n",
    "        x = F.relu(self.bn1a(self.conv1a(x))); x = F.relu(self.bn1b(self.conv1b(x))); x = self.pool1(x)\n",
    "        x = F.relu(self.bn2a(self.conv2a(x))); x = F.relu(self.bn2b(self.conv2b(x))); x = self.pool2(x)\n",
    "        x = F.relu(self.bn3a(self.conv3a(x))); x = F.relu(self.bn3b(self.conv3b(x))); x = self.pool3(x)\n",
    "        x = F.relu(self.bn4a(self.conv4a(x))); x = F.relu(self.bn4b(self.conv4b(x))); x = self.pool4(x)\n",
    "        x = F.relu(self.bn5a(self.conv5a(x))); x = F.relu(self.bn5b(self.conv5b(x)))\n",
    "        x = F.relu(self.bn6a(self.conv6a(x))); x = F.relu(self.bn6b(self.conv6b(x)))\n",
    "        return x\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self._forward_features(x); x = self.gap(x); x = x.view(-1, self.flattened_size)\n",
    "        x = F.relu(self.bn_fc1(self.fc1(x))); x = self.dropout(x); x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class GeneratedImageDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        if not os.path.isdir(root_dir):\n",
    "             raise FileNotFoundError(f\"Image directory not found: {root_dir}\")\n",
    "        self.image_files = [f for f in os.listdir(root_dir)]\n",
    "        if not self.image_files:\n",
    "             raise ValueError(f\"No valid image files found in directory: {root_dir}\")\n",
    "        print(f\"Found {len(self.image_files)} images in {root_dir}\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.root_dir, self.image_files[idx])\n",
    "        try:\n",
    "            image = Image.open(img_path).convert('RGB')\n",
    "            if image.size != (32, 32):\n",
    "                 image = image.resize((32, 32), Image.Resampling.BILINEAR) # Updated PIL resampling\n",
    "        except Exception as e:\n",
    "             print(f\"Error loading/processing image {img_path}: {e}\", file=sys.stderr)\n",
    "             return torch.zeros(3, 32, 32) # Return dummy tensor\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        # Final shape check\n",
    "        if image.shape != (3, 32, 32):\n",
    "            print(f\"Warning: Image {self.image_files[idx]} final shape {image.shape} != (3, 32, 32). Returning zeros.\", file=sys.stderr)\n",
    "            return torch.zeros(3, 32, 32)\n",
    "        return image\n",
    "\n",
    "# --- Inception Score Function (Simplified for 1 Split) ---\n",
    "\n",
    "def calculate_inception_score(preds):\n",
    "    \"\"\"Calculates the inception score for p(y|x) for all x. Assumes 1 split.\"\"\"\n",
    "    N = preds.shape[0]\n",
    "    if N == 0: return 0.0, 0.0 # Handle empty predictions\n",
    "\n",
    "\n",
    "    preds = np.clip(preds, 1e-9, 1.0)\n",
    "\n",
    "\n",
    "    p_y = np.mean(preds, axis=0)\n",
    "\n",
    "    # Compute KL divergence D_KL(p(y|x) || p(y)) for each sample x\n",
    "    kl_divs = []\n",
    "    for i in range(N):\n",
    "        p_yx = preds[i, :]\n",
    "        # entropy(pk, qk) calculates sum(pk * log(pk / qk))\n",
    "        kl_div = entropy(p_yx, p_y)\n",
    "        kl_divs.append(kl_div)\n",
    "\n",
    "    kl_divs = np.asarray(kl_divs)\n",
    "\n",
    "    mean_kl_div = np.mean(kl_divs)\n",
    "\n",
    "    mean_is = np.exp(mean_kl_div)\n",
    "\n",
    "    return mean_is\n",
    "\n",
    "# --- Main Execution ---\n",
    "if __name__ == \"__main__\":\n",
    "    if not os.path.isdir(IMAGE_DIR):\n",
    "        print(f\"Error: Image directory '{IMAGE_DIR}' not found.\", file=sys.stderr)\n",
    "        sys.exit(1)\n",
    "    if not os.path.exists(MODEL_PATH):\n",
    "        print(f\"Error: Model file '{MODEL_PATH}' not found. Train the model first.\", file=sys.stderr)\n",
    "        sys.exit(1)\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"Using device: {device}\")\n",
    "\n",
    "    # Load Model\n",
    "    model = ComplexCNN().to(device)\n",
    "\n",
    "    model.load_state_dict(torch.load(MODEL_PATH, map_location=device))\n",
    "\n",
    "    model.eval()\n",
    "    print(f\"Classifier model loaded from {MODEL_PATH} (6-Block CNN)\")\n",
    "\n",
    "    # Define Transformations\n",
    "    cifar_mean = (0.4914, 0.4822, 0.4465)\n",
    "    cifar_std = (0.2023, 0.1994, 0.2010)\n",
    "    transform_generated = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(cifar_mean, cifar_std)\n",
    "    ])\n",
    "\n",
    "    # Create DataLoader\n",
    "    dataset = GeneratedImageDataset(root_dir=IMAGE_DIR, transform=transform_generated)\n",
    "\n",
    "    dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=False,\n",
    "                            num_workers=NUM_WORKERS, pin_memory=True if device.type == 'cuda' else False)\n",
    "\n",
    "    # Run Inference\n",
    "    all_preds = []\n",
    "    print(\"Running inference on generated images using 6-Block CNN...\")\n",
    "    with torch.no_grad():\n",
    "        for images in tqdm(dataloader, desc=\"Inference\"):\n",
    "            images = images.to(device, non_blocking=True)\n",
    "\n",
    "            outputs = model(images)\n",
    "            probabilities = F.softmax(outputs, dim=1)\n",
    "\n",
    "            all_preds.append(probabilities.cpu().numpy())\n",
    "\n",
    "    if not all_preds:\n",
    "        print(\"Error: No valid predictions generated after inference.\", file=sys.stderr)\n",
    "        sys.exit(1)\n",
    "\n",
    "\n",
    "    valid_preds = [p for p in all_preds if p.shape[0] > 0]\n",
    "    \n",
    "    predictions_np = np.concatenate(valid_preds, axis=0)\n",
    "\n",
    "\n",
    "    print(f\"Successfully processed {predictions_np.shape[0]} valid images for IS calculation.\")\n",
    "    if predictions_np.shape[0] < len(dataset.image_files):\n",
    "        print(f\"Warning: Fewer predictions processed ({predictions_np.shape[0]}) than images found ({len(dataset.image_files)}). Some may have failed loading/processing.\", file=sys.stderr)\n",
    "\n",
    "    # Calculate and Print Inception Score\n",
    "    print(f\"Calculating Inception Score (Single Split) using 6-Block CNN...\")\n",
    "    is_mean = calculate_inception_score(predictions_np)\n",
    "\n",
    "    print(f\"Image Source: {IMAGE_DIR}\")\n",
    "    print(f\"Model Path:   {MODEL_PATH}\")\n",
    "    print(f\"Mean IS:      {is_mean:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "defenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
