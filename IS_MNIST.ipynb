{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import os\n",
    "\n",
    "# --- 1. Define Model Architecture ---\n",
    "\n",
    "# Let's use a simple CNN suitable for MNIST\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        # Input: 1x32x32 (Grayscale channel, Height, Width)\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1)  # 32x32 -> 32x32\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)                 # 32x32 -> 16x16\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1) # 16x16 -> 16x16\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)                 # 16x16 -> 8x8\n",
    "        # Flatten: 64 * 8 * 8 = 4096\n",
    "        self.fc1 = nn.Linear(64 * 8 * 8, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)  # 10 output classes for digits 0-9\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool1(F.relu(self.conv1(x)))\n",
    "        x = self.pool2(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 64 * 8 * 8)  # Flatten the tensor\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)  # Output raw scores (logits)\n",
    "        return x\n",
    "\n",
    "# --- Configuration ---\n",
    "batch_size = 64\n",
    "epochs = 10\n",
    "learning_rate = 0.001\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# --- 2 & 3. Load MNIST and Apply Transformations ---\n",
    "transform_32x32 = transforms.Compose([\n",
    "    transforms.Pad(2),  # Pad the 28x28 image to 32x32\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))  # MNIST mean and std dev\n",
    "])\n",
    "\n",
    "train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform_32x32)\n",
    "test_dataset = datasets.MNIST(root='./data', train=False, download=True, transform=transform_32x32)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# --- Initialize Model, Loss, Optimizer ---\n",
    "model = SimpleCNN().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# --- 4. Training Loop ---\n",
    "def train(epoch):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch_idx % 100 == 0:\n",
    "            print(f'Train Epoch: {epoch} [{batch_idx * len(data)}/{len(train_loader.dataset)} '\n",
    "                  f'({100. * batch_idx / len(train_loader):.0f}%)]\\tLoss: {loss.item():.6f}')\n",
    "\n",
    "# --- Evaluation Loop ---\n",
    "def test():\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += criterion(output, target).item()  # sum up batch loss\n",
    "            pred = output.argmax(dim=1, keepdim=True)      # get the index of the max log-probability\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    accuracy = 100. * correct / len(test_loader.dataset)\n",
    "\n",
    "    print(f'\\nTest set: Average loss: {test_loss:.4f}, Accuracy: {correct}/{len(test_loader.dataset)} '\n",
    "          f'({accuracy:.2f}%)\\n')\n",
    "    return accuracy\n",
    "\n",
    "# --- Run Training and Testing ---\n",
    "best_accuracy = 0.0\n",
    "model_save_path = 'mnist_cnn_32x32.pth'\n",
    "\n",
    "for epoch in range(1, epochs + 1):\n",
    "    train(epoch)\n",
    "    current_accuracy = test()\n",
    "\n",
    "    # --- 5. Save the Best Model ---\n",
    "    if current_accuracy > best_accuracy:\n",
    "        best_accuracy = current_accuracy\n",
    "        torch.save(model.state_dict(), model_save_path)\n",
    "        print(f\"Saved new best model to {model_save_path} with accuracy {best_accuracy:.2f}%\")\n",
    "\n",
    "print(\"Training finished.\")\n",
    "print(f\"Best model saved to {model_save_path} with accuracy {best_accuracy:.2f}%\")\n",
    "\n",
    "# --- How to Load and Use the \"Pretrained\" Model Later ---\n",
    "print(\"\\n--- Loading and Using the Trained Model ---\")\n",
    "\n",
    "# Create a new instance of the model\n",
    "loaded_model = SimpleCNN().to(device)\n",
    "\n",
    "# Load the saved weights\n",
    "if os.path.exists(model_save_path):\n",
    "    loaded_model.load_state_dict(torch.load(model_save_path, map_location=device))\n",
    "    loaded_model.eval()  # Set model to evaluation mode\n",
    "    print(f\"Model loaded successfully from {model_save_path}\")\n",
    "\n",
    "    # Example: Create a dummy 32x32 input tensor\n",
    "    dummy_input = torch.randn(1, 1, 32, 32).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = loaded_model(dummy_input)\n",
    "        probabilities = F.softmax(output, dim=1)\n",
    "        predicted_class = probabilities.argmax(dim=1)\n",
    "\n",
    "        print(f\"Dummy input prediction: Class {predicted_class.item()}\")\n",
    "        print(f\"Dummy input probabilities: {probabilities.cpu().numpy()}\")\n",
    "\n",
    "else:\n",
    "    print(f\"Model file not found at {model_save_path}. Train the model first.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier model loaded from mnist_cnn_32x32.pth (SimpleCNN for MNIST)\n",
      "Found 8192 images in ./DDPM_MNIST_Noise_Samples\n",
      "Running inference on generated images using SimpleCNN (MNIST)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 100%|██████████| 64/64 [00:02<00:00, 31.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating Inception Score (Single Split) using SimpleCNN (MNIST)...\n",
      "Dataset:      ./DDPM_MNIST_Noise_Samples\n",
      "Model Path:   mnist_cnn_32x32.pth\n",
      "Mean IS:      9.2236\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "import os\n",
    "import numpy as np\n",
    "from scipy.stats import entropy\n",
    "from tqdm import tqdm  # Optional: for progress bar\n",
    "import sys  # For exiting on error\n",
    "\n",
    "# --- Configuration (Hardcoded) ---\n",
    "IMAGE_DIR = './DDPM_MNIST_Noise_Samples'  # Directory containing the generated images\n",
    "MODEL_PATH = 'mnist_cnn_32x32.pth'      # Path to the trained classifier\n",
    "BATCH_SIZE = 128                         \n",
    "NUM_WORKERS = 1                          # DataLoader workers (adjust based on system)\n",
    "\n",
    "# --- 1. Define Model Architecture (Must match the saved model) ---\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        # Input: 1x32x32 (Grayscale channel, Height, Width)\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2) # 32x32 -> 16x16\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1) # 16x16 -> 16x16\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2) # 16x16 -> 8x8\n",
    "        # Flatten: 64 * 8 * 8 = 4096\n",
    "        self.fc1 = nn.Linear(64 * 8 * 8, 128)\n",
    "        self.fc2 = nn.Linear(128, 10) # 10 output classes for digits 0-9\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool1(F.relu(self.conv1(x)))\n",
    "        x = self.pool2(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 64 * 8 * 8) # Flatten the tensor\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x) # Output raw scores (logits)\n",
    "        return x\n",
    "\n",
    "# --- 2. Custom Dataset for Generated Images ---\n",
    "class GeneratedImageDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "\n",
    "        self.image_files = [f for f in os.listdir(root_dir)]\n",
    "        print(f\"Found {len(self.image_files)} images in {root_dir}\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.root_dir, self.image_files[idx])\n",
    "        image = Image.open(img_path).convert('L')\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image\n",
    "\n",
    "\n",
    "\n",
    "def calculate_inception_score(preds):\n",
    "    \"\"\"Calculates the inception score for p(y|x) for all x. Assumes 1 split.\"\"\"\n",
    "    N = preds.shape[0]\n",
    "    if N == 0: return 0.0, 0.0\n",
    "\n",
    "    preds = np.clip(preds, 1e-9, 1.0)\n",
    "    p_y = np.mean(preds, axis=0)\n",
    "\n",
    "    kl_divs = []\n",
    "    for i in range(N):\n",
    "        p_yx = preds[i, :]\n",
    "        kl_div = entropy(p_yx, p_y)\n",
    "        kl_divs.append(kl_div)\n",
    "\n",
    "    kl_divs = np.asarray(kl_divs)\n",
    "\n",
    "    mean_kl_div = np.mean(kl_divs)\n",
    "\n",
    "    # Optional: Cap score to prevent overflow\n",
    "    if mean_kl_div > 700: mean_is = np.exp(700)\n",
    "    else: mean_is = np.exp(mean_kl_div)\n",
    "\n",
    "    return mean_is\n",
    "\n",
    "# --- Main Execution ---\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    # --- Load Model ---\n",
    "    model = SimpleCNN().to(device) # Use the MNIST SimpleCNN\n",
    "\n",
    "    model.load_state_dict(torch.load(MODEL_PATH, map_location=device))\n",
    "\n",
    "    model.eval() # Set to evaluation mode\n",
    "    print(f\"Classifier model loaded from {MODEL_PATH} (SimpleCNN for MNIST)\")\n",
    "\n",
    "\n",
    "    transform_generated = transforms.Compose([\n",
    "        transforms.ToTensor(),                    \n",
    "        transforms.Normalize((0.1307,), (0.3081,))\n",
    "    ])\n",
    "    # --- Create DataLoader ---\n",
    "    try:\n",
    "        dataset = GeneratedImageDataset(root_dir=IMAGE_DIR, transform=transform_generated)\n",
    "    except (FileNotFoundError, ValueError) as e:\n",
    "         print(f\"Error creating dataset: {e}\", file=sys.stderr)\n",
    "         sys.exit(1)\n",
    "\n",
    "    if len(dataset) == 0:\n",
    "        print(f\"Error: No images loaded from directory {IMAGE_DIR}. Cannot calculate IS.\", file=sys.stderr)\n",
    "        sys.exit(1)\n",
    "\n",
    "    dataloader = DataLoader(dataset,\n",
    "                            batch_size=BATCH_SIZE,\n",
    "                            shuffle=False,\n",
    "                            num_workers=NUM_WORKERS,\n",
    "                            pin_memory=True if device.type == 'cuda' else False)\n",
    "\n",
    "    # --- Run Inference and Get Predictions ---\n",
    "    all_preds = []\n",
    "    print(\"Running inference on generated images using SimpleCNN (MNIST)...\")\n",
    "    with torch.no_grad():\n",
    "        for images in tqdm(dataloader, desc=\"Inference\"):\n",
    "            # Skip dummy tensors\n",
    "            if torch.equal(images, torch.zeros_like(images)):\n",
    "                 if images.sum() == 0: continue\n",
    "\n",
    "            images = images.to(device, non_blocking=True)\n",
    "\n",
    "            # Skip malformed batches (expected [B, 1, 32, 32])\n",
    "            if images.dim() != 4 or images.shape[1] != 1 or images.shape[2] != 32 or images.shape[3] != 32:\n",
    "                print(f\"Warning: Skipping batch with incorrect shape on device: {images.shape}. Expected [B, 1, 32, 32]\", file=sys.stderr)\n",
    "                continue\n",
    "\n",
    "            outputs = model(images)\n",
    "            probabilities = F.softmax(outputs, dim=1)\n",
    "            if probabilities is not None:\n",
    "                all_preds.append(probabilities.cpu().numpy())\n",
    "\n",
    "    if not all_preds:\n",
    "        print(\"Error: No valid predictions generated after inference.\", file=sys.stderr)\n",
    "        sys.exit(1)\n",
    "\n",
    "\n",
    "    valid_preds = [p for p in all_preds if p.shape[0] > 0]\n",
    "\n",
    "    predictions_np = np.concatenate(valid_preds, axis=0)\n",
    "\n",
    "\n",
    "    # Calculate and Print Inception Score\n",
    "    print(f\"Calculating Inception Score (Single Split) using SimpleCNN (MNIST)...\")\n",
    "    is_mean= calculate_inception_score(predictions_np)\n",
    "\n",
    "    print(f\"Dataset:      {IMAGE_DIR}\")\n",
    "    print(f\"Model Path:   {MODEL_PATH}\")\n",
    "    print(f\"Mean IS:      {is_mean:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "defenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
